{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import io\n",
    "import codecs\n",
    "from emot.emo_unicode import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/miki/Desktop/Projects/NLP Projects/next-word-prediction/data/raw/medium_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>image</th>\n",
       "      <th>claps</th>\n",
       "      <th>responses</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>publication</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/a-beginners-gui...</td>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.png</td>\n",
       "      <td>850</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://towardsdatascience.com/hands-on-graph-...</td>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.png</td>\n",
       "      <td>1100</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://towardsdatascience.com/how-to-use-ggpl...</td>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>A Grammar of Graphics for Python</td>\n",
       "      <td>3.png</td>\n",
       "      <td>767</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/databricks-how-...</td>\n",
       "      <td>Databricks: How to Save Files in CSV on Your L...</td>\n",
       "      <td>When I work on Python projects dealing…</td>\n",
       "      <td>4.jpeg</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://towardsdatascience.com/a-step-by-step-...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>One example of building neural…</td>\n",
       "      <td>5.jpeg</td>\n",
       "      <td>211</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                url  \\\n",
       "0   1  https://towardsdatascience.com/a-beginners-gui...   \n",
       "1   2  https://towardsdatascience.com/hands-on-graph-...   \n",
       "2   3  https://towardsdatascience.com/how-to-use-ggpl...   \n",
       "3   4  https://towardsdatascience.com/databricks-how-...   \n",
       "4   5  https://towardsdatascience.com/a-step-by-step-...   \n",
       "\n",
       "                                               title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Files in CSV on Your L...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                  subtitle   image  claps responses  \\\n",
       "0                                      NaN   1.png    850         8   \n",
       "1                                      NaN   2.png   1100        11   \n",
       "2         A Grammar of Graphics for Python   3.png    767         1   \n",
       "3  When I work on Python projects dealing…  4.jpeg    354         0   \n",
       "4          One example of building neural…  5.jpeg    211         3   \n",
       "\n",
       "   reading_time           publication        date  \n",
       "0             8  Towards Data Science  2019-05-30  \n",
       "1             9  Towards Data Science  2019-05-30  \n",
       "2             5  Towards Data Science  2019-05-30  \n",
       "3             4  Towards Data Science  2019-05-30  \n",
       "4             4  Towards Data Science  2019-05-30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.replace(r'<[^<>]*>', '', regex=True) # removing html codes and clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = '/home/miki/Desktop/Projects/NLP Projects/next-word-prediction/data/medium/output.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out, \"w\") as f:\n",
    "    f.write(\" \".join(df[\"title\"])) # saving the data as a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename): # load again the text data\n",
    "    with io.open(filename, 'r', encoding='utf8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji = list(UNICODE_EMOJI.keys()) # list of emojis that i found in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(doc):\n",
    "    \n",
    "    doc = doc.replace('--', ' ') # replace '--' with a space ' ' if any\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()] # remove remaining tokens that are not alphabetic\n",
    "    # remove an emoji from text and change into lower\n",
    "    tokens = [w for w in tokens if w not in emoji]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  r'/home/miki/Desktop/Projects/NLP Projects/next-word-prediction/data/medium/output.txt'\n",
    "doc = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric How to Use ggplot2 in Python Databricks: How to Save Files in CSV on You\n"
     ]
    }
   ],
   "source": [
    "print(doc[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'guide', 'to', 'word', 'embedding', 'with', 'gensim', 'model', 'handson', 'graph', 'neural', 'networks', 'with', 'pytorch', 'pytorch', 'geometric', 'how', 'to', 'use', 'in', 'python', 'databricks', 'how', 'to', 'save', 'files', 'in', 'csv', 'on', 'your', 'local', 'computer', 'a', 'stepbystep', 'implementation', 'of', 'gradient', 'descent', 'and', 'backpropagation', 'an', 'easy', 'introduction', 'to', 'sql', 'for', 'data', 'scientists', 'hypothesis', 'testing', 'visualized', 'introduction', 'to', 'latent', 'matrix', 'factorization', 'recommender', 'systems', 'which', 'candidate', 'is', 'the', 'best', 'at', 'twitter', 'what', 'if', 'ai', 'model', 'understanding', 'were', 'easy', 'what', 'i', 'learned', 'from', 'twotime', 'kaggle', 'grandmaster', 'abhishek', 'thakur', 'making', 'a', 'bot', 'using', 'ml', 'building', 'a', 'chrome', 'extension', 'how', 'to', 'teach', 'code', 'reinventing', 'personalization', 'for', 'customer', 'experience', 'how', 'to', 'automate', 'hyperparameter', 'optimization', 'ideas', 'design', 'methodologies', 'for', 'data', 'sprints', 'robosomm', 'chapter', 'wine', 'embeddings', 'and', 'a', 'wine', 'recommender', 'data', 'science', 'interview', 'questions', 'faster', 'training', 'for', 'efficient', 'cnns', 'buyers', 'beware', 'fake', 'product', 'reviews', 'are', 'plaguing', 'the', 'internet', 'how', 'machine', 'learning', 'can', 'help', 'to', 'spot', 'them', 'objects', 'of', 'desire', 'gigabytes', 'of', 'rbraincels', 'and', 'rtheredpill', 'how', 'data', 'management', 'practice', 'enables', 'a', 'successful', 'implementation', 'of', 'single', 'customer', 'view', 'white', 'on', 'black', 'or', 'black', 'on', 'white', 'the', 'pros', 'and', 'cons', 'of', 'dark', 'mode', 'ux', 'for', 'social', 'change', 'a', 'app', 'design', 'approach', 'is', 'an', 'experience', 'not', 'a', 'a', 'ux', 'case', 'study', 'starting', 'in', 'ux', 'after', 'some']\n",
      "Total Tokens: 48550\n",
      "Unique Tokens: 7760\n"
     ]
    }
   ],
   "source": [
    "tokens = clean_file(doc)\n",
    "#tokens = doc\n",
    "print(tokens[:200])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 48544\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 5 + 1 # for unigram\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "\t# select sequence of tokens\n",
    "\tseq = tokens[i-length:i]\n",
    "\t# convert into a line\n",
    "\tline = ' '.join(seq)\n",
    "\t# store\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a guide to word embedding with',\n",
       " 'guide to word embedding with gensim',\n",
       " 'to word embedding with gensim model',\n",
       " 'word embedding with gensim model handson',\n",
       " 'embedding with gensim model handson graph',\n",
       " 'with gensim model handson graph neural',\n",
       " 'gensim model handson graph neural networks',\n",
       " 'model handson graph neural networks with',\n",
       " 'handson graph neural networks with pytorch',\n",
       " 'graph neural networks with pytorch pytorch',\n",
       " 'neural networks with pytorch pytorch geometric',\n",
       " 'networks with pytorch pytorch geometric how',\n",
       " 'with pytorch pytorch geometric how to',\n",
       " 'pytorch pytorch geometric how to use',\n",
       " 'pytorch geometric how to use in',\n",
       " 'geometric how to use in python',\n",
       " 'how to use in python databricks',\n",
       " 'to use in python databricks how',\n",
       " 'use in python databricks how to',\n",
       " 'in python databricks how to save',\n",
       " 'python databricks how to save files',\n",
       " 'databricks how to save files in',\n",
       " 'how to save files in csv',\n",
       " 'to save files in csv on',\n",
       " 'save files in csv on your',\n",
       " 'files in csv on your local',\n",
       " 'in csv on your local computer',\n",
       " 'csv on your local computer a',\n",
       " 'on your local computer a stepbystep',\n",
       " 'your local computer a stepbystep implementation',\n",
       " 'local computer a stepbystep implementation of',\n",
       " 'computer a stepbystep implementation of gradient',\n",
       " 'a stepbystep implementation of gradient descent',\n",
       " 'stepbystep implementation of gradient descent and',\n",
       " 'implementation of gradient descent and backpropagation',\n",
       " 'of gradient descent and backpropagation an',\n",
       " 'gradient descent and backpropagation an easy',\n",
       " 'descent and backpropagation an easy introduction',\n",
       " 'and backpropagation an easy introduction to',\n",
       " 'backpropagation an easy introduction to sql',\n",
       " 'an easy introduction to sql for',\n",
       " 'easy introduction to sql for data',\n",
       " 'introduction to sql for data scientists',\n",
       " 'to sql for data scientists hypothesis',\n",
       " 'sql for data scientists hypothesis testing',\n",
       " 'for data scientists hypothesis testing visualized',\n",
       " 'data scientists hypothesis testing visualized introduction',\n",
       " 'scientists hypothesis testing visualized introduction to',\n",
       " 'hypothesis testing visualized introduction to latent',\n",
       " 'testing visualized introduction to latent matrix',\n",
       " 'visualized introduction to latent matrix factorization',\n",
       " 'introduction to latent matrix factorization recommender',\n",
       " 'to latent matrix factorization recommender systems',\n",
       " 'latent matrix factorization recommender systems which',\n",
       " 'matrix factorization recommender systems which candidate',\n",
       " 'factorization recommender systems which candidate is',\n",
       " 'recommender systems which candidate is the',\n",
       " 'systems which candidate is the best',\n",
       " 'which candidate is the best at',\n",
       " 'candidate is the best at twitter',\n",
       " 'is the best at twitter what',\n",
       " 'the best at twitter what if',\n",
       " 'best at twitter what if ai',\n",
       " 'at twitter what if ai model',\n",
       " 'twitter what if ai model understanding',\n",
       " 'what if ai model understanding were',\n",
       " 'if ai model understanding were easy',\n",
       " 'ai model understanding were easy what',\n",
       " 'model understanding were easy what i',\n",
       " 'understanding were easy what i learned',\n",
       " 'were easy what i learned from',\n",
       " 'easy what i learned from twotime',\n",
       " 'what i learned from twotime kaggle',\n",
       " 'i learned from twotime kaggle grandmaster',\n",
       " 'learned from twotime kaggle grandmaster abhishek',\n",
       " 'from twotime kaggle grandmaster abhishek thakur',\n",
       " 'twotime kaggle grandmaster abhishek thakur making',\n",
       " 'kaggle grandmaster abhishek thakur making a',\n",
       " 'grandmaster abhishek thakur making a bot',\n",
       " 'abhishek thakur making a bot using',\n",
       " 'thakur making a bot using ml',\n",
       " 'making a bot using ml building',\n",
       " 'a bot using ml building a',\n",
       " 'bot using ml building a chrome',\n",
       " 'using ml building a chrome extension',\n",
       " 'ml building a chrome extension how',\n",
       " 'building a chrome extension how to',\n",
       " 'a chrome extension how to teach',\n",
       " 'chrome extension how to teach code',\n",
       " 'extension how to teach code reinventing',\n",
       " 'how to teach code reinventing personalization',\n",
       " 'to teach code reinventing personalization for',\n",
       " 'teach code reinventing personalization for customer',\n",
       " 'code reinventing personalization for customer experience',\n",
       " 'reinventing personalization for customer experience how',\n",
       " 'personalization for customer experience how to',\n",
       " 'for customer experience how to automate',\n",
       " 'customer experience how to automate hyperparameter',\n",
       " 'experience how to automate hyperparameter optimization',\n",
       " 'how to automate hyperparameter optimization ideas',\n",
       " 'to automate hyperparameter optimization ideas design',\n",
       " 'automate hyperparameter optimization ideas design methodologies',\n",
       " 'hyperparameter optimization ideas design methodologies for',\n",
       " 'optimization ideas design methodologies for data',\n",
       " 'ideas design methodologies for data sprints',\n",
       " 'design methodologies for data sprints robosomm',\n",
       " 'methodologies for data sprints robosomm chapter',\n",
       " 'for data sprints robosomm chapter wine',\n",
       " 'data sprints robosomm chapter wine embeddings',\n",
       " 'sprints robosomm chapter wine embeddings and',\n",
       " 'robosomm chapter wine embeddings and a',\n",
       " 'chapter wine embeddings and a wine',\n",
       " 'wine embeddings and a wine recommender',\n",
       " 'embeddings and a wine recommender data',\n",
       " 'and a wine recommender data science',\n",
       " 'a wine recommender data science interview',\n",
       " 'wine recommender data science interview questions',\n",
       " 'recommender data science interview questions faster',\n",
       " 'data science interview questions faster training',\n",
       " 'science interview questions faster training for',\n",
       " 'interview questions faster training for efficient',\n",
       " 'questions faster training for efficient cnns',\n",
       " 'faster training for efficient cnns buyers',\n",
       " 'training for efficient cnns buyers beware',\n",
       " 'for efficient cnns buyers beware fake',\n",
       " 'efficient cnns buyers beware fake product',\n",
       " 'cnns buyers beware fake product reviews',\n",
       " 'buyers beware fake product reviews are',\n",
       " 'beware fake product reviews are plaguing',\n",
       " 'fake product reviews are plaguing the',\n",
       " 'product reviews are plaguing the internet',\n",
       " 'reviews are plaguing the internet how',\n",
       " 'are plaguing the internet how machine',\n",
       " 'plaguing the internet how machine learning',\n",
       " 'the internet how machine learning can',\n",
       " 'internet how machine learning can help',\n",
       " 'how machine learning can help to',\n",
       " 'machine learning can help to spot',\n",
       " 'learning can help to spot them',\n",
       " 'can help to spot them objects',\n",
       " 'help to spot them objects of',\n",
       " 'to spot them objects of desire',\n",
       " 'spot them objects of desire gigabytes',\n",
       " 'them objects of desire gigabytes of',\n",
       " 'objects of desire gigabytes of rbraincels',\n",
       " 'of desire gigabytes of rbraincels and',\n",
       " 'desire gigabytes of rbraincels and rtheredpill',\n",
       " 'gigabytes of rbraincels and rtheredpill how',\n",
       " 'of rbraincels and rtheredpill how data',\n",
       " 'rbraincels and rtheredpill how data management',\n",
       " 'and rtheredpill how data management practice',\n",
       " 'rtheredpill how data management practice enables',\n",
       " 'how data management practice enables a',\n",
       " 'data management practice enables a successful',\n",
       " 'management practice enables a successful implementation',\n",
       " 'practice enables a successful implementation of',\n",
       " 'enables a successful implementation of single',\n",
       " 'a successful implementation of single customer',\n",
       " 'successful implementation of single customer view',\n",
       " 'implementation of single customer view white',\n",
       " 'of single customer view white on',\n",
       " 'single customer view white on black',\n",
       " 'customer view white on black or',\n",
       " 'view white on black or black',\n",
       " 'white on black or black on',\n",
       " 'on black or black on white',\n",
       " 'black or black on white the',\n",
       " 'or black on white the pros',\n",
       " 'black on white the pros and',\n",
       " 'on white the pros and cons',\n",
       " 'white the pros and cons of',\n",
       " 'the pros and cons of dark',\n",
       " 'pros and cons of dark mode',\n",
       " 'and cons of dark mode ux',\n",
       " 'cons of dark mode ux for',\n",
       " 'of dark mode ux for social',\n",
       " 'dark mode ux for social change',\n",
       " 'mode ux for social change a',\n",
       " 'ux for social change a app',\n",
       " 'for social change a app design',\n",
       " 'social change a app design approach',\n",
       " 'change a app design approach is',\n",
       " 'a app design approach is an',\n",
       " 'app design approach is an experience',\n",
       " 'design approach is an experience not',\n",
       " 'approach is an experience not a',\n",
       " 'is an experience not a a',\n",
       " 'an experience not a a ux',\n",
       " 'experience not a a ux case',\n",
       " 'not a a ux case study',\n",
       " 'a a ux case study starting',\n",
       " 'a ux case study starting in',\n",
       " 'ux case study starting in ux',\n",
       " 'case study starting in ux after',\n",
       " 'study starting in ux after some',\n",
       " 'starting in ux after some proposed',\n",
       " 'in ux after some proposed color',\n",
       " 'ux after some proposed color heuristics',\n",
       " 'after some proposed color heuristics what',\n",
       " 'some proposed color heuristics what game',\n",
       " 'proposed color heuristics what game is',\n",
       " 'color heuristics what game is your',\n",
       " 'heuristics what game is your company',\n",
       " 'what game is your company playing',\n",
       " 'game is your company playing experiences',\n",
       " 'is your company playing experiences that',\n",
       " 'your company playing experiences that delight',\n",
       " 'company playing experiences that delight how',\n",
       " 'playing experiences that delight how we',\n",
       " 'experiences that delight how we emotionally',\n",
       " 'that delight how we emotionally engage',\n",
       " 'delight how we emotionally engage with',\n",
       " 'how we emotionally engage with design',\n",
       " 'we emotionally engage with design how',\n",
       " 'emotionally engage with design how i',\n",
       " 'engage with design how i learned',\n",
       " 'with design how i learned to',\n",
       " 'design how i learned to be',\n",
       " 'how i learned to be more',\n",
       " 'i learned to be more human',\n",
       " 'learned to be more human at',\n",
       " 'to be more human at one',\n",
       " 'be more human at one of',\n",
       " 'more human at one of silicon',\n",
       " 'human at one of silicon greatest',\n",
       " 'at one of silicon greatest customer',\n",
       " 'one of silicon greatest customer success',\n",
       " 'of silicon greatest customer success event',\n",
       " 'silicon greatest customer success event reflection',\n",
       " 'greatest customer success event reflection point',\n",
       " 'customer success event reflection point usability',\n",
       " 'success event reflection point usability accessibility',\n",
       " 'event reflection point usability accessibility and',\n",
       " 'reflection point usability accessibility and ethics',\n",
       " 'point usability accessibility and ethics in',\n",
       " 'usability accessibility and ethics in ux',\n",
       " 'accessibility and ethics in ux building',\n",
       " 'and ethics in ux building highquality',\n",
       " 'ethics in ux building highquality hypotheses',\n",
       " 'in ux building highquality hypotheses for',\n",
       " 'ux building highquality hypotheses for better',\n",
       " 'building highquality hypotheses for better design',\n",
       " 'highquality hypotheses for better design decisions',\n",
       " 'hypotheses for better design decisions creating',\n",
       " 'for better design decisions creating a',\n",
       " 'better design decisions creating a customerobsessed',\n",
       " 'design decisions creating a customerobsessed design',\n",
       " 'decisions creating a customerobsessed design culture',\n",
       " 'creating a customerobsessed design culture tips',\n",
       " 'a customerobsessed design culture tips for',\n",
       " 'customerobsessed design culture tips for successful',\n",
       " 'design culture tips for successful ux',\n",
       " 'culture tips for successful ux research',\n",
       " 'tips for successful ux research are',\n",
       " 'for successful ux research are preferences',\n",
       " 'successful ux research are preferences about',\n",
       " 'ux research are preferences about privacy',\n",
       " 'research are preferences about privacy relevant',\n",
       " 'are preferences about privacy relevant i',\n",
       " 'preferences about privacy relevant i just',\n",
       " 'about privacy relevant i just shut',\n",
       " 'privacy relevant i just shut down',\n",
       " 'relevant i just shut down my',\n",
       " 'i just shut down my startup',\n",
       " 'just shut down my startup what',\n",
       " 'shut down my startup what i',\n",
       " 'down my startup what i learned',\n",
       " 'my startup what i learned developers',\n",
       " 'startup what i learned developers here',\n",
       " 'what i learned developers here is',\n",
       " 'i learned developers here is the',\n",
       " 'learned developers here is the most',\n",
       " 'developers here is the most convincing',\n",
       " 'here is the most convincing reason',\n",
       " 'is the most convincing reason for',\n",
       " 'the most convincing reason for quitting',\n",
       " 'most convincing reason for quitting your',\n",
       " 'convincing reason for quitting your job',\n",
       " 'reason for quitting your job how',\n",
       " 'for quitting your job how to',\n",
       " 'quitting your job how to retain',\n",
       " 'your job how to retain more',\n",
       " 'job how to retain more from',\n",
       " 'how to retain more from the',\n",
       " 'to retain more from the books',\n",
       " 'retain more from the books you',\n",
       " 'more from the books you read',\n",
       " 'from the books you read android',\n",
       " 'the books you read android mvi',\n",
       " 'books you read android mvi with',\n",
       " 'you read android mvi with jetpack',\n",
       " 'read android mvi with jetpack compose',\n",
       " 'android mvi with jetpack compose structuring',\n",
       " 'mvi with jetpack compose structuring a',\n",
       " 'with jetpack compose structuring a nodejs',\n",
       " 'jetpack compose structuring a nodejs api',\n",
       " 'compose structuring a nodejs api in',\n",
       " 'structuring a nodejs api in an',\n",
       " 'a nodejs api in an efficient',\n",
       " 'nodejs api in an efficient way',\n",
       " 'api in an efficient way living',\n",
       " 'in an efficient way living as',\n",
       " 'an efficient way living as an',\n",
       " 'efficient way living as an empath',\n",
       " 'way living as an empath w',\n",
       " 'living as an empath w implementing',\n",
       " 'as an empath w implementing a',\n",
       " 'an empath w implementing a hexagonal',\n",
       " 'empath w implementing a hexagonal architecture',\n",
       " 'w implementing a hexagonal architecture wait',\n",
       " 'implementing a hexagonal architecture wait until',\n",
       " 'a hexagonal architecture wait until to',\n",
       " 'hexagonal architecture wait until to retire',\n",
       " 'architecture wait until to retire why',\n",
       " 'wait until to retire why fun',\n",
       " 'until to retire why fun with',\n",
       " 'to retire why fun with text',\n",
       " 'retire why fun with text to',\n",
       " 'why fun with text to image',\n",
       " 'fun with text to image in',\n",
       " 'with text to image in android',\n",
       " 'text to image in android arrays',\n",
       " 'to image in android arrays in',\n",
       " 'image in android arrays in javascript',\n",
       " 'in android arrays in javascript will',\n",
       " 'android arrays in javascript will translators',\n",
       " 'arrays in javascript will translators still',\n",
       " 'in javascript will translators still have',\n",
       " 'javascript will translators still have a',\n",
       " 'will translators still have a job',\n",
       " 'translators still have a job in',\n",
       " 'still have a job in years',\n",
       " 'have a job in years where',\n",
       " 'a job in years where when',\n",
       " 'job in years where when and',\n",
       " 'in years where when and how',\n",
       " 'years where when and how to',\n",
       " 'where when and how to submit',\n",
       " 'when and how to submit your',\n",
       " 'and how to submit your writing',\n",
       " 'how to submit your writing ways',\n",
       " 'to submit your writing ways to',\n",
       " 'submit your writing ways to increase',\n",
       " 'your writing ways to increase your',\n",
       " 'writing ways to increase your engagement',\n",
       " 'ways to increase your engagement rate',\n",
       " 'to increase your engagement rate on',\n",
       " 'increase your engagement rate on instagram',\n",
       " 'your engagement rate on instagram three',\n",
       " 'engagement rate on instagram three ways',\n",
       " 'rate on instagram three ways great',\n",
       " 'on instagram three ways great leaders',\n",
       " 'instagram three ways great leaders show',\n",
       " 'three ways great leaders show they',\n",
       " 'ways great leaders show they care',\n",
       " 'great leaders show they care about',\n",
       " 'leaders show they care about their',\n",
       " 'show they care about their team',\n",
       " 'they care about their team india',\n",
       " 'care about their team india has',\n",
       " 'about their team india has a',\n",
       " 'their team india has a digital',\n",
       " 'team india has a digital content',\n",
       " 'india has a digital content market',\n",
       " 'has a digital content market no',\n",
       " 'a digital content market no approval',\n",
       " 'digital content market no approval needed',\n",
       " 'content market no approval needed setting',\n",
       " 'market no approval needed setting boundaries',\n",
       " 'no approval needed setting boundaries not',\n",
       " 'approval needed setting boundaries not giving',\n",
       " 'needed setting boundaries not giving explanations',\n",
       " 'setting boundaries not giving explanations the',\n",
       " 'boundaries not giving explanations the dirty',\n",
       " 'not giving explanations the dirty business',\n",
       " 'giving explanations the dirty business of',\n",
       " 'explanations the dirty business of yoga',\n",
       " 'the dirty business of yoga a',\n",
       " 'dirty business of yoga a future',\n",
       " 'business of yoga a future in',\n",
       " 'of yoga a future in esports',\n",
       " 'yoga a future in esports nsxt',\n",
       " 'a future in esports nsxt security',\n",
       " 'future in esports nsxt security with',\n",
       " 'in esports nsxt security with ansible',\n",
       " 'esports nsxt security with ansible basic',\n",
       " 'nsxt security with ansible basic firewall',\n",
       " 'security with ansible basic firewall rules',\n",
       " 'with ansible basic firewall rules neuroaesthetics',\n",
       " 'ansible basic firewall rules neuroaesthetics understanding',\n",
       " 'basic firewall rules neuroaesthetics understanding our',\n",
       " 'firewall rules neuroaesthetics understanding our perception',\n",
       " 'rules neuroaesthetics understanding our perception of',\n",
       " 'neuroaesthetics understanding our perception of beauty',\n",
       " 'understanding our perception of beauty why',\n",
       " 'our perception of beauty why sometimes',\n",
       " 'perception of beauty why sometimes better',\n",
       " 'of beauty why sometimes better to',\n",
       " 'beauty why sometimes better to sell',\n",
       " 'why sometimes better to sell picks',\n",
       " 'sometimes better to sell picks and',\n",
       " 'better to sell picks and shovels',\n",
       " 'to sell picks and shovels than',\n",
       " 'sell picks and shovels than mine',\n",
       " 'picks and shovels than mine for',\n",
       " 'and shovels than mine for gold',\n",
       " 'shovels than mine for gold routes',\n",
       " 'than mine for gold routes in',\n",
       " 'mine for gold routes in rails',\n",
       " 'for gold routes in rails investing',\n",
       " 'gold routes in rails investing inside',\n",
       " 'routes in rails investing inside the',\n",
       " 'in rails investing inside the ooda',\n",
       " 'rails investing inside the ooda loop',\n",
       " 'investing inside the ooda loop why',\n",
       " 'inside the ooda loop why i',\n",
       " 'the ooda loop why i take',\n",
       " 'ooda loop why i take my',\n",
       " 'loop why i take my clothes',\n",
       " 'why i take my clothes off',\n",
       " 'i take my clothes off in',\n",
       " 'take my clothes off in front',\n",
       " 'my clothes off in front of',\n",
       " 'clothes off in front of strangers',\n",
       " 'off in front of strangers the',\n",
       " 'in front of strangers the time',\n",
       " 'front of strangers the time i',\n",
       " 'of strangers the time i was',\n",
       " 'strangers the time i was hacked',\n",
       " 'the time i was hacked by',\n",
       " 'time i was hacked by mr',\n",
       " 'i was hacked by mr sh',\n",
       " 'was hacked by mr sh c',\n",
       " 'hacked by mr sh c rvalues',\n",
       " 'by mr sh c rvalues move',\n",
       " 'mr sh c rvalues move semantics',\n",
       " 'sh c rvalues move semantics and',\n",
       " 'c rvalues move semantics and copy',\n",
       " 'rvalues move semantics and copy elision',\n",
       " 'move semantics and copy elision death',\n",
       " 'semantics and copy elision death stranding',\n",
       " 'and copy elision death stranding is',\n",
       " 'copy elision death stranding is about',\n",
       " 'elision death stranding is about the',\n",
       " 'death stranding is about the fracturing',\n",
       " 'stranding is about the fracturing soul',\n",
       " 'is about the fracturing soul of',\n",
       " 'about the fracturing soul of america',\n",
       " 'the fracturing soul of america a',\n",
       " 'fracturing soul of america a framework',\n",
       " 'soul of america a framework for',\n",
       " 'of america a framework for creativity',\n",
       " 'america a framework for creativity is',\n",
       " 'a framework for creativity is mr',\n",
       " 'framework for creativity is mr your',\n",
       " 'for creativity is mr your goals',\n",
       " 'creativity is mr your goals depend',\n",
       " 'is mr your goals depend on',\n",
       " 'mr your goals depend on how',\n",
       " 'your goals depend on how you',\n",
       " 'goals depend on how you set',\n",
       " 'depend on how you set your',\n",
       " 'on how you set your intentions',\n",
       " 'how you set your intentions i',\n",
       " 'you set your intentions i was',\n",
       " 'set your intentions i was miserable',\n",
       " 'your intentions i was miserable as',\n",
       " 'intentions i was miserable as a',\n",
       " 'i was miserable as a suburban',\n",
       " 'was miserable as a suburban stayhome',\n",
       " 'miserable as a suburban stayhome mom',\n",
       " 'as a suburban stayhome mom talk',\n",
       " 'a suburban stayhome mom talk to',\n",
       " 'suburban stayhome mom talk to the',\n",
       " 'stayhome mom talk to the internet',\n",
       " 'mom talk to the internet with',\n",
       " 'talk to the internet with ip',\n",
       " 'to the internet with ip addresses',\n",
       " 'the internet with ip addresses why',\n",
       " 'internet with ip addresses why reflection',\n",
       " 'with ip addresses why reflection opens',\n",
       " 'ip addresses why reflection opens up',\n",
       " 'addresses why reflection opens up your',\n",
       " 'why reflection opens up your world',\n",
       " 'reflection opens up your world to',\n",
       " 'opens up your world to the',\n",
       " 'up your world to the present',\n",
       " 'your world to the present and',\n",
       " 'world to the present and future',\n",
       " 'to the present and future where',\n",
       " 'the present and future where did',\n",
       " 'present and future where did you',\n",
       " 'and future where did you get',\n",
       " 'future where did you get that',\n",
       " 'where did you get that that',\n",
       " 'did you get that that is',\n",
       " 'you get that that is so',\n",
       " 'get that that is so cool',\n",
       " 'that that is so cool an',\n",
       " 'that is so cool an ode',\n",
       " 'is so cool an ode to',\n",
       " 'so cool an ode to ancient',\n",
       " 'cool an ode to ancient technology',\n",
       " 'an ode to ancient technology that',\n",
       " 'ode to ancient technology that is',\n",
       " 'to ancient technology that is getting',\n",
       " 'ancient technology that is getting a',\n",
       " 'technology that is getting a new',\n",
       " 'that is getting a new look',\n",
       " 'is getting a new look we',\n",
       " 'getting a new look we all',\n",
       " 'a new look we all need',\n",
       " 'new look we all need a',\n",
       " 'look we all need a coach',\n",
       " 'we all need a coach objectivity',\n",
       " 'all need a coach objectivity is',\n",
       " 'need a coach objectivity is the',\n",
       " 'a coach objectivity is the most',\n",
       " 'coach objectivity is the most important',\n",
       " 'objectivity is the most important design',\n",
       " 'is the most important design skill',\n",
       " 'the most important design skill oop',\n",
       " 'most important design skill oop how',\n",
       " 'important design skill oop how i',\n",
       " 'design skill oop how i would',\n",
       " 'skill oop how i would explain',\n",
       " 'oop how i would explain it',\n",
       " 'how i would explain it to',\n",
       " 'i would explain it to my',\n",
       " 'would explain it to my grandmother',\n",
       " 'explain it to my grandmother understanding',\n",
       " 'it to my grandmother understanding menopause',\n",
       " 'to my grandmother understanding menopause how',\n",
       " 'my grandmother understanding menopause how can',\n",
       " 'grandmother understanding menopause how can technology',\n",
       " 'understanding menopause how can technology help',\n",
       " 'menopause how can technology help curves',\n",
       " 'how can technology help curves how',\n",
       " 'can technology help curves how stored',\n",
       " 'technology help curves how stored in',\n",
       " 'help curves how stored in computers',\n",
       " 'curves how stored in computers goals',\n",
       " 'how stored in computers goals vs',\n",
       " 'stored in computers goals vs milestones',\n",
       " 'in computers goals vs milestones working',\n",
       " 'computers goals vs milestones working with',\n",
       " 'goals vs milestones working with the',\n",
       " 'vs milestones working with the voices',\n",
       " 'milestones working with the voices in',\n",
       " 'working with the voices in my',\n",
       " 'with the voices in my head',\n",
       " 'the voices in my head why',\n",
       " 'voices in my head why you',\n",
       " 'in my head why you should',\n",
       " 'my head why you should never',\n",
       " 'head why you should never undermine',\n",
       " 'why you should never undermine the',\n",
       " 'you should never undermine the meaning',\n",
       " 'should never undermine the meaning of',\n",
       " 'never undermine the meaning of your',\n",
       " 'undermine the meaning of your life',\n",
       " 'the meaning of your life how',\n",
       " 'meaning of your life how to',\n",
       " 'of your life how to limit',\n",
       " 'your life how to limit your',\n",
       " 'life how to limit your exposure',\n",
       " 'how to limit your exposure to',\n",
       " 'to limit your exposure to the',\n",
       " 'limit your exposure to the surveillance',\n",
       " 'your exposure to the surveillance capitalism',\n",
       " 'exposure to the surveillance capitalism features',\n",
       " 'to the surveillance capitalism features vs',\n",
       " 'the surveillance capitalism features vs benefits',\n",
       " 'surveillance capitalism features vs benefits vs',\n",
       " 'capitalism features vs benefits vs outcomes',\n",
       " 'features vs benefits vs outcomes leverage',\n",
       " 'vs benefits vs outcomes leverage all',\n",
       " 'benefits vs outcomes leverage all three',\n",
       " 'vs outcomes leverage all three to',\n",
       " 'outcomes leverage all three to boost',\n",
       " 'leverage all three to boost your',\n",
       " 'all three to boost your sales',\n",
       " 'three to boost your sales the',\n",
       " 'to boost your sales the threat',\n",
       " 'boost your sales the threat jobs',\n",
       " 'your sales the threat jobs pose',\n",
       " 'sales the threat jobs pose to',\n",
       " 'the threat jobs pose to mental',\n",
       " 'threat jobs pose to mental health',\n",
       " 'jobs pose to mental health why',\n",
       " 'pose to mental health why you',\n",
       " 'to mental health why you need',\n",
       " 'mental health why you need to',\n",
       " 'health why you need to stop',\n",
       " 'why you need to stop obsessing',\n",
       " 'you need to stop obsessing about',\n",
       " 'need to stop obsessing about your',\n",
       " 'to stop obsessing about your mvp',\n",
       " 'stop obsessing about your mvp how',\n",
       " 'obsessing about your mvp how to',\n",
       " 'about your mvp how to succeed',\n",
       " 'your mvp how to succeed at',\n",
       " 'mvp how to succeed at hiring',\n",
       " 'how to succeed at hiring stuck',\n",
       " 'to succeed at hiring stuck in',\n",
       " 'succeed at hiring stuck in your',\n",
       " 'at hiring stuck in your past',\n",
       " 'hiring stuck in your past and',\n",
       " 'stuck in your past and blocked',\n",
       " 'in your past and blocked from',\n",
       " 'your past and blocked from your',\n",
       " 'past and blocked from your future',\n",
       " 'and blocked from your future anxiety',\n",
       " 'blocked from your future anxiety attacks',\n",
       " 'from your future anxiety attacks vs',\n",
       " 'your future anxiety attacks vs panic',\n",
       " 'future anxiety attacks vs panic attacks',\n",
       " 'anxiety attacks vs panic attacks is',\n",
       " 'attacks vs panic attacks is booming',\n",
       " 'vs panic attacks is booming and',\n",
       " 'panic attacks is booming and why',\n",
       " 'attacks is booming and why why',\n",
       " 'is booming and why why you',\n",
       " 'booming and why why you must',\n",
       " 'and why why you must use',\n",
       " 'why why you must use video',\n",
       " 'why you must use video for',\n",
       " 'you must use video for your',\n",
       " 'must use video for your business',\n",
       " 'use video for your business why',\n",
       " 'video for your business why the',\n",
       " 'for your business why the tech',\n",
       " 'your business why the tech giants',\n",
       " 'business why the tech giants save',\n",
       " 'why the tech giants save the',\n",
       " 'the tech giants save the news',\n",
       " 'tech giants save the news online',\n",
       " 'giants save the news online business',\n",
       " 'save the news online business owning',\n",
       " 'the news online business owning a',\n",
       " 'news online business owning a walk',\n",
       " 'online business owning a walk in',\n",
       " 'business owning a walk in the',\n",
       " 'owning a walk in the park',\n",
       " 'a walk in the park how',\n",
       " 'walk in the park how to',\n",
       " 'in the park how to provide',\n",
       " 'the park how to provide support',\n",
       " 'park how to provide support to',\n",
       " 'how to provide support to a',\n",
       " 'to provide support to a grieving',\n",
       " 'provide support to a grieving friend',\n",
       " 'support to a grieving friend turn',\n",
       " 'to a grieving friend turn your',\n",
       " 'a grieving friend turn your productivity',\n",
       " 'grieving friend turn your productivity on',\n",
       " 'friend turn your productivity on autopilot',\n",
       " 'turn your productivity on autopilot keys',\n",
       " 'your productivity on autopilot keys to',\n",
       " 'productivity on autopilot keys to away',\n",
       " 'on autopilot keys to away daily',\n",
       " 'autopilot keys to away daily stress',\n",
       " 'keys to away daily stress the',\n",
       " 'to away daily stress the call',\n",
       " 'away daily stress the call for',\n",
       " 'daily stress the call for a',\n",
       " 'stress the call for a new',\n",
       " 'the call for a new device',\n",
       " 'call for a new device for',\n",
       " 'for a new device for data',\n",
       " 'a new device for data scientists',\n",
       " 'new device for data scientists an',\n",
       " 'device for data scientists an introduction',\n",
       " 'for data scientists an introduction to',\n",
       " 'data scientists an introduction to python',\n",
       " 'scientists an introduction to python sets',\n",
       " 'an introduction to python sets part',\n",
       " 'introduction to python sets part iii',\n",
       " 'to python sets part iii negativity',\n",
       " 'python sets part iii negativity the',\n",
       " 'sets part iii negativity the master',\n",
       " 'part iii negativity the master timethief',\n",
       " 'iii negativity the master timethief how',\n",
       " 'negativity the master timethief how to',\n",
       " 'the master timethief how to live',\n",
       " 'master timethief how to live in',\n",
       " 'timethief how to live in the',\n",
       " 'how to live in the present',\n",
       " 'to live in the present and',\n",
       " 'live in the present and make',\n",
       " 'in the present and make your',\n",
       " 'the present and make your time',\n",
       " 'present and make your time count',\n",
       " 'and make your time count look',\n",
       " 'make your time count look ma',\n",
       " 'your time count look ma no',\n",
       " 'time count look ma no hands',\n",
       " 'count look ma no hands raised',\n",
       " 'look ma no hands raised on',\n",
       " 'ma no hands raised on nintendo',\n",
       " 'no hands raised on nintendo my',\n",
       " 'hands raised on nintendo my story',\n",
       " 'raised on nintendo my story on',\n",
       " 'on nintendo my story on bilingualism',\n",
       " 'nintendo my story on bilingualism i',\n",
       " 'my story on bilingualism i know',\n",
       " 'story on bilingualism i know what',\n",
       " 'on bilingualism i know what to',\n",
       " 'bilingualism i know what to do',\n",
       " 'i know what to do with',\n",
       " 'know what to do with my',\n",
       " 'what to do with my hands',\n",
       " 'to do with my hands tips',\n",
       " 'do with my hands tips for',\n",
       " 'with my hands tips for sticking',\n",
       " 'my hands tips for sticking to',\n",
       " 'hands tips for sticking to new',\n",
       " 'tips for sticking to new habits',\n",
       " 'for sticking to new habits when',\n",
       " 'sticking to new habits when travelling',\n",
       " 'to new habits when travelling the',\n",
       " 'new habits when travelling the law',\n",
       " 'habits when travelling the law of',\n",
       " 'when travelling the law of reciprocity',\n",
       " 'travelling the law of reciprocity how',\n",
       " 'the law of reciprocity how giving',\n",
       " 'law of reciprocity how giving without',\n",
       " 'of reciprocity how giving without expectation',\n",
       " 'reciprocity how giving without expectation makes',\n",
       " 'how giving without expectation makes sense',\n",
       " 'giving without expectation makes sense in',\n",
       " 'without expectation makes sense in business',\n",
       " 'expectation makes sense in business should',\n",
       " 'makes sense in business should you',\n",
       " 'sense in business should you skip',\n",
       " 'in business should you skip the',\n",
       " 'business should you skip the caffeine',\n",
       " 'should you skip the caffeine guaranteed',\n",
       " 'you skip the caffeine guaranteed jobs',\n",
       " 'skip the caffeine guaranteed jobs how',\n",
       " 'the caffeine guaranteed jobs how great',\n",
       " 'caffeine guaranteed jobs how great is',\n",
       " 'guaranteed jobs how great is the',\n",
       " 'jobs how great is the need',\n",
       " 'how great is the need concepts',\n",
       " 'great is the need concepts from',\n",
       " 'is the need concepts from network',\n",
       " 'the need concepts from network science',\n",
       " 'need concepts from network science to',\n",
       " 'concepts from network science to make',\n",
       " 'from network science to make and',\n",
       " 'network science to make and strengthen',\n",
       " 'science to make and strengthen key',\n",
       " 'to make and strengthen key connections',\n",
       " 'make and strengthen key connections how',\n",
       " 'and strengthen key connections how to',\n",
       " 'strengthen key connections how to be',\n",
       " 'key connections how to be terrible',\n",
       " 'connections how to be terrible at',\n",
       " 'how to be terrible at everything',\n",
       " 'to be terrible at everything user',\n",
       " 'be terrible at everything user research',\n",
       " 'terrible at everything user research at',\n",
       " 'at everything user research at a',\n",
       " 'everything user research at a techstars',\n",
       " 'user research at a techstars startups',\n",
       " 'research at a techstars startups company',\n",
       " 'at a techstars startups company are',\n",
       " 'a techstars startups company are we',\n",
       " 'techstars startups company are we losing',\n",
       " 'startups company are we losing our',\n",
       " 'company are we losing our reallife',\n",
       " 'are we losing our reallife relationships',\n",
       " 'we losing our reallife relationships with',\n",
       " 'losing our reallife relationships with each',\n",
       " 'our reallife relationships with each other',\n",
       " 'reallife relationships with each other how',\n",
       " 'relationships with each other how to',\n",
       " 'with each other how to get',\n",
       " 'each other how to get the',\n",
       " 'other how to get the throatclearing',\n",
       " 'how to get the throatclearing out',\n",
       " 'to get the throatclearing out of',\n",
       " 'get the throatclearing out of your',\n",
       " 'the throatclearing out of your writing',\n",
       " 'throatclearing out of your writing your',\n",
       " 'out of your writing your first',\n",
       " 'of your writing your first fans',\n",
       " 'your writing your first fans lessons',\n",
       " 'writing your first fans lessons learned',\n",
       " 'your first fans lessons learned from',\n",
       " 'first fans lessons learned from one',\n",
       " 'fans lessons learned from one year',\n",
       " 'lessons learned from one year of',\n",
       " 'learned from one year of consistent',\n",
       " 'from one year of consistent writing',\n",
       " 'one year of consistent writing brands',\n",
       " 'year of consistent writing brands are',\n",
       " 'of consistent writing brands are artifacts',\n",
       " 'consistent writing brands are artifacts of',\n",
       " 'writing brands are artifacts of culture',\n",
       " 'brands are artifacts of culture zero',\n",
       " 'are artifacts of culture zero resistance',\n",
       " 'artifacts of culture zero resistance creativity',\n",
       " 'of culture zero resistance creativity how',\n",
       " 'culture zero resistance creativity how should',\n",
       " 'zero resistance creativity how should the',\n",
       " 'resistance creativity how should the ecb',\n",
       " 'creativity how should the ecb normalize',\n",
       " 'how should the ecb normalize monetary',\n",
       " 'should the ecb normalize monetary policy',\n",
       " 'the ecb normalize monetary policy strokes',\n",
       " 'ecb normalize monetary policy strokes of',\n",
       " 'normalize monetary policy strokes of fortune',\n",
       " 'monetary policy strokes of fortune finding',\n",
       " 'policy strokes of fortune finding your',\n",
       " 'strokes of fortune finding your peak',\n",
       " 'of fortune finding your peak productivity',\n",
       " 'fortune finding your peak productivity how',\n",
       " 'finding your peak productivity how to',\n",
       " 'your peak productivity how to edit',\n",
       " 'peak productivity how to edit your',\n",
       " 'productivity how to edit your scenes',\n",
       " 'how to edit your scenes the',\n",
       " 'to edit your scenes the right',\n",
       " 'edit your scenes the right way',\n",
       " 'your scenes the right way a',\n",
       " 'scenes the right way a reason',\n",
       " 'the right way a reason for',\n",
       " 'right way a reason for being',\n",
       " 'way a reason for being using',\n",
       " 'a reason for being using belief',\n",
       " 'reason for being using belief statements',\n",
       " 'for being using belief statements to',\n",
       " 'being using belief statements to uncover',\n",
       " 'using belief statements to uncover your',\n",
       " 'belief statements to uncover your purpose',\n",
       " 'statements to uncover your purpose lessons',\n",
       " 'to uncover your purpose lessons on',\n",
       " 'uncover your purpose lessons on motivation',\n",
       " 'your purpose lessons on motivation from',\n",
       " 'purpose lessons on motivation from the',\n",
       " 'lessons on motivation from the greek',\n",
       " 'on motivation from the greek hero',\n",
       " 'motivation from the greek hero odysseus',\n",
       " 'from the greek hero odysseus scheduled',\n",
       " 'the greek hero odysseus scheduled happiness',\n",
       " 'greek hero odysseus scheduled happiness why',\n",
       " 'hero odysseus scheduled happiness why funded',\n",
       " 'odysseus scheduled happiness why funded startups',\n",
       " 'scheduled happiness why funded startups should',\n",
       " 'happiness why funded startups should always',\n",
       " 'why funded startups should always be',\n",
       " 'funded startups should always be innovating',\n",
       " 'startups should always be innovating why',\n",
       " 'should always be innovating why a',\n",
       " 'always be innovating why a style',\n",
       " 'be innovating why a style guide',\n",
       " 'innovating why a style guide is',\n",
       " 'why a style guide is just',\n",
       " 'a style guide is just good',\n",
       " 'style guide is just good business',\n",
       " 'guide is just good business do',\n",
       " 'is just good business do you',\n",
       " 'just good business do you even',\n",
       " 'good business do you even have',\n",
       " 'business do you even have an',\n",
       " 'do you even have an inner',\n",
       " 'you even have an inner artist',\n",
       " 'even have an inner artist how',\n",
       " 'have an inner artist how to',\n",
       " 'an inner artist how to start',\n",
       " 'inner artist how to start going',\n",
       " 'artist how to start going from',\n",
       " 'how to start going from freelancer',\n",
       " 'to start going from freelancer to',\n",
       " 'start going from freelancer to becoming',\n",
       " 'going from freelancer to becoming an',\n",
       " 'from freelancer to becoming an entrepreneur',\n",
       " 'freelancer to becoming an entrepreneur unexpected',\n",
       " 'to becoming an entrepreneur unexpected things',\n",
       " 'becoming an entrepreneur unexpected things i',\n",
       " 'an entrepreneur unexpected things i miss',\n",
       " 'entrepreneur unexpected things i miss about',\n",
       " 'unexpected things i miss about freelance',\n",
       " 'things i miss about freelance the',\n",
       " 'i miss about freelance the power',\n",
       " 'miss about freelance the power of',\n",
       " 'about freelance the power of unconventional',\n",
       " 'freelance the power of unconventional marketing',\n",
       " 'the power of unconventional marketing learn',\n",
       " 'power of unconventional marketing learn from',\n",
       " 'of unconventional marketing learn from my',\n",
       " 'unconventional marketing learn from my mistake',\n",
       " 'marketing learn from my mistake never',\n",
       " 'learn from my mistake never delete',\n",
       " 'from my mistake never delete your',\n",
       " 'my mistake never delete your website',\n",
       " 'mistake never delete your website literary',\n",
       " 'never delete your website literary biography',\n",
       " 'delete your website literary biography how',\n",
       " 'your website literary biography how childhood',\n",
       " 'website literary biography how childhood books',\n",
       " 'literary biography how childhood books shape',\n",
       " 'biography how childhood books shape us',\n",
       " 'how childhood books shape us what',\n",
       " 'childhood books shape us what if',\n",
       " 'books shape us what if your',\n",
       " 'shape us what if your morals',\n",
       " 'us what if your morals clash',\n",
       " 'what if your morals clash with',\n",
       " 'if your morals clash with your',\n",
       " 'your morals clash with your work',\n",
       " 'morals clash with your work you',\n",
       " 'clash with your work you might',\n",
       " 'with your work you might want',\n",
       " 'your work you might want to',\n",
       " 'work you might want to put',\n",
       " 'you might want to put that',\n",
       " 'might want to put that biodegradable',\n",
       " 'want to put that biodegradable fork',\n",
       " 'to put that biodegradable fork down',\n",
       " 'put that biodegradable fork down getting',\n",
       " 'that biodegradable fork down getting anxiety',\n",
       " 'biodegradable fork down getting anxiety over',\n",
       " 'fork down getting anxiety over things',\n",
       " 'down getting anxiety over things you',\n",
       " 'getting anxiety over things you fear',\n",
       " 'anxiety over things you fear rare',\n",
       " 'over things you fear rare earth',\n",
       " 'things you fear rare earth exports',\n",
       " 'you fear rare earth exports difficult',\n",
       " 'fear rare earth exports difficult clients',\n",
       " 'rare earth exports difficult clients are',\n",
       " 'earth exports difficult clients are very',\n",
       " 'exports difficult clients are very much',\n",
       " 'difficult clients are very much like',\n",
       " 'clients are very much like toddlers',\n",
       " 'are very much like toddlers what',\n",
       " 'very much like toddlers what i',\n",
       " 'much like toddlers what i want',\n",
       " 'like toddlers what i want to',\n",
       " 'toddlers what i want to tell',\n",
       " 'what i want to tell my',\n",
       " 'i want to tell my younger',\n",
       " 'want to tell my younger self',\n",
       " 'to tell my younger self why',\n",
       " 'tell my younger self why we',\n",
       " 'my younger self why we rock',\n",
       " 'younger self why we rock the',\n",
       " 'self why we rock the cradle',\n",
       " 'why we rock the cradle and',\n",
       " 'we rock the cradle and walk',\n",
       " 'rock the cradle and walk our',\n",
       " 'the cradle and walk our dreams',\n",
       " 'cradle and walk our dreams side',\n",
       " 'and walk our dreams side by',\n",
       " 'walk our dreams side by side',\n",
       " 'our dreams side by side is',\n",
       " 'dreams side by side is facebook',\n",
       " 'side by side is facebook listening',\n",
       " 'by side is facebook listening to',\n",
       " 'side is facebook listening to your',\n",
       " 'is facebook listening to your private',\n",
       " 'facebook listening to your private conversations',\n",
       " 'listening to your private conversations and',\n",
       " 'to your private conversations and selling',\n",
       " 'your private conversations and selling that',\n",
       " 'private conversations and selling that data',\n",
       " 'conversations and selling that data to',\n",
       " 'and selling that data to advertisers',\n",
       " 'selling that data to advertisers i',\n",
       " 'that data to advertisers i was',\n",
       " 'data to advertisers i was a',\n",
       " 'to advertisers i was a human',\n",
       " 'advertisers i was a human book',\n",
       " 'i was a human book mistakes',\n",
       " 'was a human book mistakes i',\n",
       " 'a human book mistakes i learned',\n",
       " 'human book mistakes i learned while',\n",
       " 'book mistakes i learned while blogging',\n",
       " 'mistakes i learned while blogging about',\n",
       " 'i learned while blogging about blockchain',\n",
       " 'learned while blogging about blockchain the',\n",
       " 'while blogging about blockchain the past',\n",
       " 'blogging about blockchain the past years',\n",
       " 'about blockchain the past years should',\n",
       " 'blockchain the past years should the',\n",
       " 'the past years should the grow',\n",
       " 'past years should the grow up',\n",
       " 'years should the grow up digitally',\n",
       " 'should the grow up digitally highlight',\n",
       " 'the grow up digitally highlight the',\n",
       " 'grow up digitally highlight the person',\n",
       " 'up digitally highlight the person not',\n",
       " 'digitally highlight the person not just',\n",
       " 'highlight the person not just the',\n",
       " 'the person not just the diagnosis',\n",
       " 'person not just the diagnosis why',\n",
       " 'not just the diagnosis why comparing',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_file(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w', encoding='utf8')\n",
    "\tfile.write(data)\n",
    "\tfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/home/miki/Desktop/Projects/NLP Projects/next-word-prediction/data/final/data5.txt'\n",
    "save_file(sequences, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('words': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c11d362ad6055b3b06b699b2bedaffd36824fd7ca8323bae7a4d667d4cc44aad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
